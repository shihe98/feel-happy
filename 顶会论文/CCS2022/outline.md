# 2022 CCS 关注内容
## 人工智能的特性
1. is your explanation stable? a robustness evaluation framework for feature attribution.<br>
关键点：用特征归因理解神经网络的可解释性，即某个决策和关键特征有关系。当前大部分算法旨在提升模型的忠实度。<br>
问题：现实环境中存在许多随机噪声，会干扰图像分类任务的特征归因；解释算法容易受到对抗性攻击，为恶意干扰的输入生成相同的解释。<br>
方案：提出了用于特征归因的中值检验（MeTFA），在理论上量化不确定性并提高解释算法的稳定性，适用于任何特征归因方法。<br>
功能：（1）检查一个特征重要或不重要，并生成显著映射以可视化结果（2）计算特征归因分数的置信区间，并生成平滑映射以提高解释的稳定性。<br>
优点：（1）改善了解释的视觉质量，显著降低了不稳定性，同时保持了原始方法的忠实度。**[万金油强化]**（2）两个典型应用来展示MeTFA在应用中的潜力。**[定量评估忠实度与防御效果]**
