# 2022 CCS 关注内容
## 人工智能的特性
1. is your explanation stable? a robustness evaluation framework for feature attribution.<br>
*关键点*：用特征归因理解神经网络的可解释性，即某个决策和关键特征有关系。当前大部分算法旨在提升模型的忠实度。<br>
*问题*：现实环境中存在许多随机噪声，会干扰图像分类任务的特征归因；解释算法容易受到对抗性攻击，为恶意干扰的输入生成相同的解释。<br>
*方案*：提出了用于特征归因的中值检验（MeTFA），在理论上量化不确定性并提高解释算法的稳定性，适用于任何特征归因方法。<br>
*功能*：（1）检查一个特征重要或不重要，并生成显著映射以可视化结果。（2）计算特征归因分数的置信区间，并生成平滑映射以提高解释的稳定性。<br>
*优点*：（1）改善了解释的视觉质量，显著降低了不稳定性，同时保持了原始方法的忠实度。**[万金油强化]**（2）两个典型应用来展示MeTFA在应用中的潜力。**[定量评估忠实度与防御效果]**
2. AI/ML for Network Security: The Emperor has no Clothes<br>
*问题*：基于机器学习（ML）的网络流量检测方案过于黑盒，网络运营商不愿信任并将部署它们。因为这些模型容易出现欠规范化问题（**未能以足够详细的方式指定模型**），导致模型表现出意想不到的糟糕行为。<br>
*痛点*：开发可解释的ML解决方案（例如决策树），帮助解释黑盒模型的决策过程。合成高保真度又易于理解的可解释模型是具有挑战性的。<br>
*方案*：合成高保真度和低复杂度的决策树，帮助网络运营商判断他们的ML模型是否欠缺规范。Trustee将现有ML模型和训练数据集作为输入，生成高保真度、易于解释的决策树以及相关信任报告作为输出。<br>
*优点*：利用已发布的、完全可复制的ML模型，来识别模型欠规范化的三个常见实例，即快捷学习的证据、伪相关性的存在以及对分布外异常样本的脆弱性。<br>
*PS*：把人工智能的规范化作为整体的任务，利用决策树做一个模型级别的检测。作者直接把赛道提高一个维度，属于首发性工作。

## 人工智能&隐私保护
1. Are Attribute Inference Attacks Just Imputation?<br>
*问题*：模型会暴露其训练数据中的敏感信息。在属性推断攻击中，攻击者可以接触某些训练数据的一部分并访问训练后的模型，从而推断这些记录中敏感特征的未知值。<br>
*方案*：研究了一种属性推断的细粒度变体，敏感值推断。攻击者的目标是从候选集中识别出[具有特定敏感值的未知属性的]某些记录。此方案明确地比较了属性推断与数据插补，后者在各种关于训练数据的假设下捕获了训练的统计分布。<br>
*结论*：（1）先前的属性推断方法并未揭示模型中关于训练数据的更多信息。攻击者甚至不需要访问模型，与训练属性推理攻击所需的底层分布知识相同即可。（2）没有模型就学不到的东西，黑盒推理攻击很少学到。（3）论文中的白盒攻击可以识别出具有敏感值属性的一些记录[没有访问模型的情况下不会预测这些记录]。<br>
*PS*：差分隐私训练和删除易受攻击的记录等防御措施，并未减轻这种隐私风险。作者提出了属性推理的一种变体，探究此攻击的一些性质。

2. Auditing Membership Leakages of Multi-Exit Networks<br>
*问题*：并非所有输入都需要相同的计算成本来产生可靠的预测，多出口网络正逐渐受到关注。主干模型具有早期退出的能力，允许在模型的中间层进行预测。然而，目前的各种设计主要考虑资源使用效率和预测准确性两个方面，尚未探讨由此产生的隐私风险。
*方案*：首次从成员泄露的角度分析了多出口网络的隐私问题。首先，利用现有的攻击方法来量化多出口网络在成员泄露方面的脆弱性。然后，提出了一种混合攻击，利用出口信息来提高现有攻击的性能。
*结论*：多出口网络在成员泄露方面的脆弱性较低，附加在主干模型上的退出（数量和深度）与攻击性能高度相关。在三种不同对手设置下，评估了混合攻击引起的成员泄露威胁，得到一个无模型和无数据的敌手。最终，考虑了一种专门针对多出口网络的防御机制 TimeGuard。
*PS*：完整地考虑某个威胁问题，考虑如何改进[强调威胁]，寻找解决方案[比较完整的研究]。
